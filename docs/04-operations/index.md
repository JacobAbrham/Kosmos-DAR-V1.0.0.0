# Volume IV: Operations & FinOps

**The "Run" - Monitoring, Incident Response, Cost Control**

> "In production, everything that can break, will break. Be ready."

---

## ğŸ“‹ Overview

Volume IV defines the **operational procedures**, **incident response protocols**, and **financial operations** for running AI systems in KOSMOS. This volume ensures systems run reliably, cost-effectively, and with proper observability.

### Purpose

This volume provides:

- **Infrastructure** - Kubernetes, database operations, disaster recovery
- **Observability** - Metrics, logging, tracing, alerting, dashboards
- **FinOps Metrics** - Cost tracking and optimization for AI systems
- **Drift Detection** - Monitoring for model and data drift
- **SLA/SLO Definitions** - Service level objectives and agreements
- **Incident Response** - Runbooks for common AI system incidents

---

## ğŸ“š Contents

### [Infrastructure](infrastructure/README.md)
Platform and deployment operations:
- [Kubernetes Architecture](infrastructure/kubernetes.md) - K3s cluster configuration
- [Deployment Architecture](infrastructure/deployment.md) - CI/CD pipelines, canary deployments
- [Disaster Recovery](infrastructure/disaster-recovery.md) - RTO/RPO, backup procedures
- [Database Operations](infrastructure/database-ops.md) - PostgreSQL, Dragonfly runbooks

### [Observability](observability/README.md)
Monitoring and visibility:
- [Metrics Reference](observability/metrics.md) - Prometheus metrics, recording rules
- [Logging Standards](observability/logging.md) - Structured logging, Loki queries
- [Distributed Tracing](observability/tracing.md) - OpenTelemetry, Tempo
- [Alerting Rules](observability/alerting.md) - Alert definitions, routing
- [Dashboards](observability/dashboards.md) - Grafana dashboard catalog
- [LLM Observability](observability/llm-observability.md) - Langfuse integration

### [FinOps Metrics](finops-metrics.md)
Cost management and optimization:
- Cost per inference tracking
- Token usage monitoring
- Budget alerts and forecasting
- Optimization strategies
- Cloud cost allocation

### [Drift Detection](drift-detection.md)
Monitoring for system degradation:
- Model performance drift
- Data distribution drift
- Concept drift detection
- Alert thresholds
- Remediation workflows

### [SLA/SLO Definitions](sla-slo.md)
Service level objectives:
- Availability targets
- Performance thresholds
- Error rate budgets
- Escalation procedures
- Reporting cadence

### [Incident Response](incident-response/README.md)
Runbooks for critical incidents:
- [Prompt Injection Attacks](incident-response/prompt-injection.md)
- [Loop Detection & Remediation](incident-response/loop-detection.md)
- General incident response framework
- Post-mortem templates

---

## ğŸ¯ Operational Principles

### 1. **Observe Everything**
Comprehensive monitoring is the foundation of reliable operations.

### 2. **Fail Gracefully**
Systems should degrade predictably with clear error messages.

### 3. **Automate Recovery**
Automated remediation reduces mean time to recovery (MTTR).

### 4. **Budget Consciously**
AI operations can be expensive. Track and optimize costs continuously.

### 5. **Learn from Incidents**
Every incident is an opportunity to improve systems and processes.

### 6. **Test Disaster Recovery**
Regular chaos engineering and disaster recovery drills are essential.

---

## ğŸ“Š Operations Dashboard

### System Health Overview

```
KOSMOS Operations Dashboard
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Service Availability: 99.95% âœ… (Target: 99.9%)
Error Rate: 0.3% âœ… (Target: <1%)
P95 Latency: 1.2s âœ… (Target: <2s)
Cost per Request: $0.042 ğŸŸ¡ (Budget: $0.040)

Active Incidents: 0
Open Alerts: 2 (both low severity)
Deployed Models: 5
Daily Requests: 2.5M

Last Deployment: 2 hours ago
Next Scheduled Maintenance: In 3 days
```

### Cost Dashboard

> **Note:** This dashboard shows the **Pilot Tier** budget (~$50k/month for limited deployment).
> For full enterprise cost projections (~$250k/month at scale), see [FinOps Metrics](finops-metrics.md).

```
AI Operations Cost Summary (Pilot Tier)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Monthly Spend: $45,230 (of $50,000 budget)
Daily Average: $1,507
Projected Month-End: $47,715 âœ…

Cost Breakdown:
â”œâ”€â”€ Model Inference: $32,400 (72%)
â”œâ”€â”€ Training: $8,100 (18%)
â”œâ”€â”€ Storage: $2,700 (6%)
â””â”€â”€ Networking: $2,030 (4%)

Top Cost Drivers:
1. Document Summarizer: $18,500
2. Code Reviewer: $12,300
3. Sentiment Analyzer: $6,600
```

---

## ğŸ”„ Operations Lifecycle

```mermaid
graph TB
    A[Deploy] --> B[Monitor]
    B --> C{Alert?}
    C -->|Yes| D[Investigate]
    C -->|No| B
    D --> E{Incident?}
    E -->|Yes| F[Execute Runbook]
    E -->|No| G[Tune Alerts]
    F --> H[Resolve]
    H --> I[Post-Mortem]
    I --> J[Improve]
    J --> A
    G --> B
```

---

## ğŸš¨ Alert Severity Levels

### Critical (P0)
- **Response Time:** < 5 minutes
- **Examples:** 
  - Service completely down
  - Data breach detected
  - Critical security vulnerability
- **Actions:** 
  - Page on-call engineer immediately
  - Engage incident commander
  - Execute emergency runbook

### High (P1)
- **Response Time:** < 15 minutes
- **Examples:**
  - Elevated error rates (>5%)
  - Severe performance degradation
  - Fairness violations detected
- **Actions:**
  - Notify on-call engineer
  - Begin investigation
  - Prepare rollback if needed

### Medium (P2)
- **Response Time:** < 1 hour
- **Examples:**
  - Minor performance degradation
  - Non-critical errors increasing
  - Cost overruns detected
- **Actions:**
  - Create ticket
  - Investigate during business hours
  - Monitor for escalation

### Low (P3)
- **Response Time:** < 1 day
- **Examples:**
  - Minor anomalies
  - Informational alerts
  - Capacity planning warnings
- **Actions:**
  - Log for trending
  - Address in next sprint
  - Document for future reference

---

## ğŸ“‹ On-Call Responsibilities

### On-Call Engineer Duties

**During Shift:**
- âœ… Monitor dashboards actively
- âœ… Respond to alerts per SLA
- âœ… Execute incident runbooks
- âœ… Document all actions taken
- âœ… Escalate when needed
- âœ… Conduct handoff briefing

**Shift Duration:** 7 days (rotates weekly)

**Escalation Path:**
1. On-Call Engineer (you)
2. Senior Engineer / Team Lead
3. Engineering Manager
4. VP Engineering / CTO

**On-Call Kit:**
- Access to production systems
- Runbook documentation
- Escalation contact list
- VPN credentials
- Monitoring dashboard access
- Incident management tool

---

## ğŸ› ï¸ Operational Tools

### Monitoring & Observability

**Metrics:**
```bash
# Prometheus for metrics
prometheus_endpoint: https://prometheus.nuvanta.com

# Key metrics to watch
- model_requests_total
- model_request_duration_seconds
- model_errors_total
- model_cost_per_request
- model_fairness_score
```

**Logging:**
```bash
# Centralized logging
elasticsearch: https://logs.nuvanta.com

# Log aggregation
- Application logs (stdout/stderr)
- Access logs
- Error logs
- Audit logs
```

**Tracing:**
```bash
# Distributed tracing
jaeger: https://tracing.nuvanta.com

# Trace every request
- Request ID propagation
- Service dependencies
- Latency breakdown
```

### Incident Management

```bash
# PagerDuty integration
pagerduty_service: kosmos-ai-ops

# Status page
status_page: https://status.nuvanta.com

# Post-mortem template
template: docs/04-operations/incident-response/post-mortem-template.md
```

---

## ğŸ“Š Key Performance Indicators

### Reliability Metrics

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| **Availability** | 99.9% | 99.95% | ğŸŸ¢ Exceeding |
| **Error Rate** | <1% | 0.3% | ğŸŸ¢ Good |
| **P95 Latency** | <2s | 1.2s | ğŸŸ¢ Good |
| **MTTR** | <1h | 45min | ğŸŸ¢ Good |
| **Deployment Frequency** | Daily | 3x/week | ğŸŸ¡ Improving |

### Cost Metrics (Pilot Tier)

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| **Monthly Budget** | $50k | $45k | ğŸŸ¢ Under Budget |
| **Cost per Request** | $0.040 | $0.042 | ğŸŸ¡ Slightly Over |
| **Token Efficiency** | >80% | 78% | ğŸŸ¡ Needs Improvement |
| **Waste Reduction** | >90% | 92% | ğŸŸ¢ Good |

*Enterprise tier targets: See [FinOps Metrics](finops-metrics.md) for full-scale projections.*

### Quality Metrics

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| **Model Accuracy** | >90% | 92% | ğŸŸ¢ Good |
| **Fairness Score** | >0.8 | 0.85 | ğŸŸ¢ Good |
| **Data Quality** | >95% | 96% | ğŸŸ¢ Good |
| **Drift Detection** | <5% | 2% | ğŸŸ¢ Good |

---

## ğŸ”— Related Documentation

- **[Volume II: Architecture](../02-architecture/index.md)** - System design
- **[Volume III: Engineering](../03-engineering/index.md)** - Deployment procedures
- **[Canary Playbooks](../03-engineering/canary-playbooks.md)** - Safe deployments
- **[Kill Switch Protocol](../01-governance/kill-switch-protocol.md)** - Emergency shutdown

---

## ğŸ“ Operations Contacts

| Role | Contact | Responsibility |
|------|---------|----------------|
| **On-Call Engineer** | oncall@nuvanta-holding.com | 24/7 incident response |
| **DevOps Lead** | devops@nuvanta-holding.com | Operations leadership |
| **SRE Team** | sre@nuvanta-holding.com | Reliability engineering |
| **FinOps Lead** | finops@nuvanta-holding.com | Cost optimization |
| **Security Operations** | secops@nuvanta-holding.com | Security incidents |

---

## ğŸš€ Getting Started

### For Operations Engineers

1. **Read** [SLA/SLO Definitions](sla-slo.md)
2. **Study** [Incident Response](incident-response/README.md) runbooks
3. **Review** [Drift Detection](drift-detection.md) procedures
4. **Understand** [FinOps Metrics](finops-metrics.md)
5. **Complete** on-call training

### For On-Call Engineers

1. Verify access to all monitoring tools
2. Review current system status
3. Read recent incident post-mortems
4. Test alert delivery mechanisms
5. Familiarize with escalation procedures

### For Managers

1. Review SLA compliance reports
2. Check cost trends and forecasts
3. Assess team workload
4. Plan capacity increases
5. Review incident trends

---

## ğŸ“… Operational Cadence

### Daily
- Morning standup (9:00 AM)
- On-call handoff (if shift change)
- Review overnight alerts
- Check cost trends

### Weekly
- Operations review meeting
- Cost optimization review
- Alert tuning session
- On-call rotation

### Monthly
- SLA/SLO review
- Incident trend analysis
- Capacity planning
- Budget reconciliation
- Disaster recovery drill

### Quarterly
- Architecture review
- Tool evaluation
- Process improvements
- Team retrospective

---

## ğŸ“ˆ Continuous Improvement

### Feedback Loops

```mermaid
graph LR
    A[Monitor] --> B[Detect Issue]
    B --> C[Respond]
    C --> D[Resolve]
    D --> E[Post-Mortem]
    E --> F[Action Items]
    F --> G[Implement]
    G --> A
```

### Improvement Metrics

- Incident frequency trending down
- MTTR decreasing
- Alert accuracy improving
- Cost efficiency increasing
- Customer satisfaction rising

---

**Last Updated:** 2025-12-11  
**Document Owner:** DevOps Lead  
**Next Review:** 2026-03-11

---

[â† Back to Home](../index.md) | [Volume III: Engineering â†’](../03-engineering/index.md) | [Volume V: Human Factors â†’](../05-human-factors/index.md)
